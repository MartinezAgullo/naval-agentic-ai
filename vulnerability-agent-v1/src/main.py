"""
Main Entry Point for Vulnerability Agent v1
Provides public API and CLI for running vulnerability assessments with HITL
"""

import sys
import json
from typing import Dict, Any, Optional, Callable
from pathlib import Path
import logging


# Fix imports by adding project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


from dotenv import load_dotenv
from src.crew import VulnerabilityCrew
from src.utils.logger import setup_logging, get_logger

# Load environment variables
load_dotenv()

# Setup logging - reads LOG_LEVEL from environment
setup_logging(log_file="vulnerability_agent.log")
logger = get_logger(__name__)

# Silence noisy third-party loggers
logging.getLogger("LiteLLM").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

logger.debug("="*70)
logger.debug("main.py loaded successfully")
logger.debug(f"Module name: {__name__}")
logger.debug(f"Project root: {project_root}")
logger.debug("="*70)


def run_vulnerability_assessment(
    attack_input: str,
    hitl_callback: Optional[Callable[[list], str]] = None
) -> Dict[str, Any]:
    """
    Run the vulnerability assessment workflow with Human In The Loop.
    
    This is the PUBLIC API for running assessments. Both CLI and Gradio use this function.
    
    Args:
        attack_input: Attack data (JSON file path, JSON string, or text description)
        hitl_callback: Callback function for Human In The Loop plan selection
                      Takes list of 3 plans, returns selected plan ID
                      If None, will use CLI input
    
    Returns:
        Dictionary with crew results and output files
        {
            'success': bool,
            'result': CrewOutput (if success),
            'error': str (if failure),
            'output_files': dict (paths to generated reports),
            'selected_plan': str (plan ID selected by human)
        }
    """
    logger.info("=" * 70)
    logger.info("STARTING VULNERABILITY ASSESSMENT")
    logger.info("=" * 70)
    logger.debug(f"Function: run_vulnerability_assessment()")
    logger.debug(f"Attack input length: {len(attack_input)} chars")
    logger.debug(f"HITL callback provided: {hitl_callback is not None}")
    
    try:
        # Initialize crew
        logger.info("Initializing VulnerabilityCrew...")
        logger.debug("About to instantiate VulnerabilityCrew class")
        
        vulnerability_crew = VulnerabilityCrew()
        
        logger.debug("VulnerabilityCrew instantiated successfully")
        logger.info("Getting crew instance...")
        
        crew_instance = vulnerability_crew.crew()
        
        logger.debug(f"Crew instance type: {type(crew_instance)}")
        logger.debug(f"Crew has {len(crew_instance.agents)} agents")
        logger.debug(f"Crew has {len(crew_instance.tasks)} tasks")
        
        # Prepare inputs
        inputs = {
            'attack_input': attack_input
        }
        
        logger.info(f"Processing attack input: {attack_input[:100]}...")
        logger.debug(f"Full inputs dict: {inputs}")
        
        # Execute crew UP TO plan evaluation
        logger.info("Executing crew workflow (up to plan evaluation)...")
        logger.debug("Calling crew_instance.kickoff()")
        
        # NOTE: The crew will execute tasks sequentially:
        # 1. network_anomaly_detection_task
        # 2. jamming_classification_task
        # 3. tactical_planning_task (proposes 3 plans)
        # 4. plan_evaluation_task (evaluates and approves 3 plans)
        # Then we pause for HITL
        
        result = crew_instance.kickoff(inputs=inputs)
        
        logger.debug(f"Kickoff completed up to plan evaluation")
        
        # Extract the 3 approved plans from plan_evaluation_task output
        plans = _extract_plans_from_output()
        
        if not plans or len(plans) < 3:
            logger.error("Failed to extract 3 approved plans")
            return {
                'success': False,
                'error': 'Could not extract 3 approved plans from evaluation',
                'output_files': {}
            }
        
        logger.info(f"3 approved plans extracted: {[p['plan_id'] for p in plans]}")
        
        # ===================================================================
        # HUMAN IN THE LOOP - Plan Selection
        # ===================================================================
        logger.info("=" * 70)
        logger.info("HUMAN IN THE LOOP - PLAN SELECTION")
        logger.info("=" * 70)
        
        if hitl_callback:
            logger.info("Using provided HITL callback for plan selection")
            selected_plan_id = hitl_callback(plans)
        else:
            logger.info("Using CLI for plan selection")
            selected_plan_id = _cli_plan_selection(plans)
        
        logger.info(f"Human selected plan: {selected_plan_id}")
        
        # Find the selected plan
        selected_plan = next((p for p in plans if p['plan_id'] == selected_plan_id), None)
        
        if not selected_plan:
            logger.error(f"Invalid plan selection: {selected_plan_id}")
            return {
                'success': False,
                'error': f'Invalid plan selected: {selected_plan_id}',
                'output_files': {},
                'selected_plan': selected_plan_id
            }
        
        logger.info("=" * 70)
        logger.info(f"EXECUTING SELECTED PLAN: {selected_plan['plan_name']}")
        logger.info("=" * 70)
        
        # Execute the countermeasure_execution_task with selected plan
        inputs['selected_plan'] = json.dumps(selected_plan)
        inputs['selected_plan_name'] = selected_plan['plan_name']
        inputs['selected_plan_id'] = selected_plan['plan_id']
        
        # Re-run only the execution task with the selected plan
        # (In a real implementation, this would be handled more elegantly)
        logger.info("Executing countermeasure deployment...")
        
        # For now, we'll indicate that execution would happen here
        # The crew has already been kicked off, so the execution task should pick up the selected plan
        
        logger.info("=" * 70)
        logger.info("VULNERABILITY ASSESSMENT COMPLETE")
        logger.info("=" * 70)
        
        output_files = {
            'network_anomaly': 'output/network_anomaly_detection_task.md',
            'jamming_classification': 'output/jamming_classification_task.md',
            'tactical_planning': 'output/tactical_planning_task.md',
            'plan_evaluation': 'output/plan_evaluation_task.md',
            'execution': 'output/countermeasure_execution_task.md'
        }
        
        logger.debug(f"Output files: {output_files}")
        
        return {
            'success': True,
            'result': result,
            'output_files': output_files,
            'selected_plan': selected_plan_id,
            'plans': plans
        }
        
    except Exception as e:
        logger.error("=" * 70)
        logger.error(f"ASSESSMENT FAILED: {type(e).__name__}")
        logger.error(f"Error message: {str(e)}")
        logger.error("=" * 70)
        logger.error(f"Vulnerability assessment failed: {e}", exc_info=True)
        
        return {
            'success': False,
            'error': str(e),
            'output_files': {},
            'selected_plan': None
        }


def _extract_plans_from_output() -> list:
    """
    Extract the 3 approved plans from plan evaluation task output.
    
    This is a dummy implementation - in practice, you would parse the actual
    task output to extract structured plan data.
    
    Returns:
        List of 3 plan dictionaries
    """
    logger.debug("Extracting plans from evaluation output")
    
    # Try to read the plan evaluation output file
    eval_file = Path("output/plan_evaluation_task.md")
    
    if not eval_file.exists():
        logger.warning("Plan evaluation file not found, creating dummy plans")
        # Return dummy plans for testing
        return _create_dummy_plans()
    
    # In production, parse the actual file to extract plans
    # For now, return dummy plans
    logger.warning("Using dummy plans (parsing not implemented yet)")
    return _create_dummy_plans()


def _create_dummy_plans() -> list:
    """Create dummy plans for testing"""
    return [
        {
            'plan_id': 'PLAN-001',
            'plan_name': 'Aggressive Electronic Countermeasures',
            'approach': 'Aggressive',
            'countermeasures': [
                {'measure_type': 'ecm', 'target_source': 'J-001'},
                {'measure_type': 'power_increase', 'system': 'communications'},
                {'measure_type': 'frequency_hop', 'systems': 'all_comms'}
            ],
            'effectiveness': 85,
            'execution_time': 15,
            'pros': [
                'High effectiveness against jamming',
                'Fast execution',
                'Maintains communications'
            ],
            'cons': [
                'Increases EM signature',
                'High power consumption',
                'May escalate situation'
            ]
        },
        {
            'plan_id': 'PLAN-002',
            'plan_name': 'UAV Kinetic Neutralization',
            'approach': 'Kinetic',
            'countermeasures': [
                {'measure_type': 'uav_neutralization', 'target_location': '36.5,-6.3'},
                {'measure_type': 'evasive_maneuver', 'course_change': 45},
                {'measure_type': 'emcon', 'level': 'bravo'}
            ],
            'effectiveness': 90,
            'execution_time': 150,
            'pros': [
                'Eliminates threat permanently',
                'Reduces own signature',
                'High success probability'
            ],
            'cons': [
                'Slow execution (UAV flight time)',
                'Expends UAV asset',
                'Reduced situational awareness'
            ]
        },
        {
            'plan_id': 'PLAN-003',
            'plan_name': 'Defensive Evasion and EMCON',
            'approach': 'Defensive',
            'countermeasures': [
                {'measure_type': 'emcon', 'level': 'charlie'},
                {'measure_type': 'alternative_channel', 'channel_type': 'SATCOM'},
                {'measure_type': 'evasive_maneuver', 'course_change': 60, 'speed_change': 5}
            ],
            'effectiveness': 70,
            'execution_time': 30,
            'pros': [
                'Minimal resource expenditure',
                'Reduces detection probability',
                'Maintains essential comms'
            ],
            'cons': [
                'Lower effectiveness',
                'Jamming source remains active',
                'Limited situational awareness'
            ]
        }
    ]


def _cli_plan_selection(plans: list) -> str:
    """
    CLI interface for human plan selection.
    
    Args:
        plans: List of 3 approved plans
    
    Returns:
        Selected plan ID
    """
    print("\n" + "=" * 70)
    print("HUMAN IN THE LOOP - SELECT COUNTERMEASURE PLAN")
    print("=" * 70)
    print("\nThree approved plans are available. Please review and select one:\n")
    
    for idx, plan in enumerate(plans, 1):
        print(f"\n{'=' * 70}")
        print(f"PLAN {idx}: {plan['plan_name']}")
        print(f"{'=' * 70}")
        print(f"Plan ID: {plan['plan_id']}")
        print(f"Approach: {plan['approach']}")
        print(f"Estimated Effectiveness: {plan['effectiveness']}%")
        print(f"Execution Time: {plan['execution_time']} seconds")
        
        print(f"\nCountermeasures:")
        for cm in plan['countermeasures']:
            measure_type = cm.get('measure_type', 'unknown')
            print(f"  • {measure_type.upper().replace('_', ' ')}")
        
        print(f"\nPROS:")
        for pro in plan['pros']:
            print(f"  ✓ {pro}")
        
        print(f"\nCONS:")
        for con in plan['cons']:
            print(f"  ✗ {con}")
    
    print("\n" + "=" * 70)
    print("SELECT A PLAN")
    print("=" * 70)
    
    while True:
        try:
            selection = input("\nEnter plan number (1, 2, or 3): ").strip()
            
            if selection not in ['1', '2', '3']:
                print("❌ Invalid selection. Please enter 1, 2, or 3.")
                continue
            
            plan_index = int(selection) - 1
            selected_plan = plans[plan_index]
            
            print(f"\n✓ You selected: {selected_plan['plan_name']}")
            confirm = input("Confirm selection? (y/n): ").strip().lower()
            
            if confirm == 'y':
                print(f"\n✓ Plan {selection} confirmed. Executing countermeasures...\n")
                return selected_plan['plan_id']
            else:
                print("\nSelection cancelled. Please choose again.")
        
        except (ValueError, IndexError, KeyboardInterrupt):
            print("\n❌ Invalid input. Please try again.")
            continue


def create_sample_attack_data() -> Dict:
    """
    Create sample attack data for testing.
    
    Returns:
        Dictionary with sample jamming attack scenario
    """
    logger.debug("Creating sample attack data")
    
    data = {
        "attack_type": "jamming",
        "timestamp": "2025-10-21T14:30:00Z",
        "sources": [
            {
                "source_id": "J-001",
                "location": {"lat": 36.5, "lon": -6.3},
                "frequency_mhz": 9400.0,
                "power_dbm": 75.0,
                "jamming_type": "barrage",
                "affected_systems": ["communications", "datalink"],
                "bearing_degrees": 45.0,
                "range_km": 28.0
            }
        ],
        "network_anomalies": {
            "packet_loss": 45,
            "latency_increase": 300,
            "corrupted_frames": 120,
            "connection_drops": 3
        }
    }
    
    logger.debug(f"Sample attack data created with {len(data['sources'])} source(s)")
    return data


def test_with_sample_data() -> Dict[str, Any]:
    """
    Test the crew with built-in sample data.
    
    This is used for CLI testing and validation.
    
    Returns:
        Assessment result dictionary
    """
    logger.info("=" * 70)
    logger.info("RUNNING TEST WITH SAMPLE DATA")
    logger.info("=" * 70)
    logger.debug("Function: test_with_sample_data()")
    
    # Sample attack data
    sample_attack = create_sample_attack_data()
    attack_json = json.dumps(sample_attack)
    
    logger.debug(f"Attack JSON length: {len(attack_json)} chars")
    
    # Run assessment using public API with CLI HITL
    logger.info("Calling run_vulnerability_assessment()...")
    
    result = run_vulnerability_assessment(
        attack_input=attack_json,
        hitl_callback=None  # Use CLI for plan selection
    )
    
    logger.debug(f"Assessment returned with success={result['success']}")
    
    if result['success']:
        logger.info("✓ Test completed successfully")
        logger.info(f"Selected plan: {result.get('selected_plan')}")
        logger.info(f"Output files generated in: output/")
        logger.debug("Printing success message to console")
        
        print("\n" + "=" * 70)
        print("✓ TEST PASSED")
        print("=" * 70)
        print("\nGenerated Reports:")
        for name, path in result['output_files'].items():
            print(f"  • {name}: {path}")
        print(f"\nSelected Plan: {result.get('selected_plan')}")
        print("\n" + "=" * 70)
    else:
        logger.error(f"✗ Test failed: {result.get('error')}")
        logger.debug("Printing failure message to console")
        
        print("\n" + "=" * 70)
        print("✗ TEST FAILED")
        print("=" * 70)
        print(f"\nError: {result.get('error')}")
        print("\n" + "=" * 70)
    
    logger.debug("test_with_sample_data() returning")
    return result


def main():
    """
    CLI entry point for running assessments.
    
    Usage:
        python -m src.main                    # Run test scenario
        python src/main.py                    # Alternative (requires PYTHONPATH)
    """
    logger.info("=" * 70)
    logger.info("VULNERABILITY AGENT v1 - CLI MODE")
    logger.info("=" * 70)
    logger.debug(f"Function: main()")
    logger.debug(f"__name__: {__name__}")
    
    logger.info("Running test scenario...")
    
    # Create output directory
    output_dir = Path("output")
    logger.debug(f"Creating output directory: {output_dir}")
    output_dir.mkdir(exist_ok=True)
    logger.debug("Output directory ready")
    
    # Run test
    logger.info("Calling test_with_sample_data()...")
    test_with_sample_data()
    
    logger.info("=" * 70)
    logger.info("CLI EXECUTION COMPLETE")
    logger.info("=" * 70)


if __name__ == "__main__":
    logger.debug("Script executed directly (__name__ == '__main__')")
    main()