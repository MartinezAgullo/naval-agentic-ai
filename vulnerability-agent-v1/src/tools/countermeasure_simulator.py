"""
Countermeasure Simulator Tool - FIXED VERSION
Simulates effectiveness of proposed countermeasures against jamming attacks

FIX: Handle both lowercase and capitalized JSON keys from Tactical Planning Agent
ISSUE: Agent outputs "Countermeasures" but tool expected "countermeasures"
"""

import json
import os
import random
from typing import Type, Optional, Dict, List
from pathlib import Path
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

from src.utils.logger import get_logger

logger = get_logger(__name__)

# Get absolute path to jamming database
PROJECT_ROOT = Path(__file__).parent.parent.parent
JAMMING_DB_PATH = PROJECT_ROOT / 'config' / 'jamming_database.json'


class CountermeasureSimulatorInput(BaseModel):
    """Input schema for countermeasure simulation"""
    plan_data: str = Field(
        ...,
        description="JSON string with countermeasure plan including measures and target sources"
    )


class CountermeasureSimulator(BaseTool):
    """Simulates countermeasure effectiveness against jamming attacks"""
    
    name: str = "Countermeasure Simulator"
    description: str = (
        "Simulates the effectiveness of proposed countermeasures against detected jamming. "
        "Evaluates success probability, execution time, and resource requirements. "
        "Input: plan_data (JSON string with countermeasure plan)"
    )
    args_schema: Type[BaseModel] = CountermeasureSimulatorInput
    
    _jamming_db: Dict = {}
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._jamming_db = self._load_jamming_database()
    
    def _load_jamming_database(self) -> Dict:
        """Load jamming database for countermeasure data"""
        try:
            logger.debug(f"Loading jamming database from: {JAMMING_DB_PATH}")
            
            if not JAMMING_DB_PATH.exists():
                logger.error(f"Jamming database not found at: {JAMMING_DB_PATH}")
                return {}
            
            with open(JAMMING_DB_PATH, 'r') as f:
                db = json.load(f)
            
            logger.info("Jamming database loaded successfully")
            return db
            
        except Exception as e:
            logger.error(f"Failed to load jamming database: {e}")
            return {}
    
    def _run(self, plan_data: str) -> str:
        try:
            logger.info("Simulating countermeasure effectiveness")
            
            # Parse plan data
            data = self._parse_plan_data(plan_data)
            
            if not data:
                logger.error("Failed to parse plan data")
                return "ERROR: Could not parse countermeasure plan data"
            
            # FIXED: Extract plan details (handle both lowercase and capitalized keys)
            plan_id = data.get('plan_id') or data.get('Plan_ID') or data.get('Plan_Name', 'UNKNOWN')
            countermeasures = data.get('countermeasures') or data.get('Countermeasures', [])
            target_sources = data.get('target_sources') or data.get('Target_Sources', [])
            
            logger.debug(f"Parsed plan_id: {plan_id}")
            logger.debug(f"Found {len(countermeasures)} countermeasures")
            
            # FIXED: Normalize countermeasure dictionaries to lowercase keys
            normalized_countermeasures = []
            for cm in countermeasures:
                normalized_cm = {
                    'measure_type': cm.get('measure_type') or cm.get('Type') or cm.get('type', 'unknown'),
                    'target_source': cm.get('target_source') or cm.get('Target') or cm.get('target', None),
                    'parameters': cm.get('parameters') or cm.get('Parameters') or cm.get('params', {}),
                    'estimated_effectiveness': (
                        cm.get('estimated_effectiveness') or 
                        cm.get('Estimated_Effectiveness') or 
                        cm.get('effectiveness', 75)
                    )
                }
                normalized_countermeasures.append(normalized_cm)
                logger.debug(f"Normalized countermeasure: {normalized_cm['measure_type']}")
            
            if not normalized_countermeasures:
                logger.warning("No countermeasures found in plan data")
                logger.warning(f"Raw data keys: {list(data.keys())}")
                return json.dumps({
                    "status": "failed",
                    "reason": "No countermeasures provided in plan",
                    "action": "skip"
                })
            
            logger.info(f"Simulating plan {plan_id} with {len(normalized_countermeasures)} countermeasures")
            
            # Simulate each countermeasure
            simulation_results = []
            for cm in normalized_countermeasures:
                result = self._simulate_countermeasure(cm, target_sources)
                simulation_results.append(result)
            
            # Calculate overall plan effectiveness
            overall_effectiveness = self._calculate_overall_effectiveness(simulation_results)
            
            # Build report
            report = self._build_simulation_report(
                plan_id,
                simulation_results,
                overall_effectiveness,
                data
            )
            
            logger.info(f"âœ“ Simulation complete - Overall effectiveness: {overall_effectiveness:.1f}%")
            
            return report
            
        except Exception as e:
            logger.error(f"Countermeasure simulation error: {e}", exc_info=True)
            return f"ERROR in countermeasure simulation: {str(e)}"
    
    def _parse_plan_data(self, plan_data: str) -> Optional[Dict]:
        """Parse plan data from file or JSON string"""
        try:
            if os.path.exists(plan_data):
                logger.debug(f"Reading plan data from file: {plan_data}")
                with open(plan_data, 'r') as f:
                    return json.load(f)
            
            logger.debug("Parsing plan data as JSON string")
            return json.loads(plan_data)
        
        except Exception as e:
            logger.error(f"Failed to parse plan data: {e}")
            return None
    
    def _simulate_countermeasure(
        self,
        countermeasure: Dict,
        target_sources: List[Dict]
    ) -> Dict:
        """Simulate a single countermeasure"""
        
        measure_type = countermeasure.get('measure_type', 'unknown')
        target_source_id = countermeasure.get('target_source', None)
        
        logger.debug(f"Simulating {measure_type} countermeasure")
        
        # Get countermeasure library data
        cm_library = self._jamming_db.get('countermeasure_library', {})
        cm_data = cm_library.get(measure_type, {})
        
        # Base effectiveness (from database or estimate)
        base_effectiveness = countermeasure.get('estimated_effectiveness', 75)
        
        # Add random variation (-5 to +10) for realism
        variation = random.uniform(-5, 10)
        simulated_effectiveness = max(0, min(100, base_effectiveness + variation))
        
        # Get execution parameters
        execution_time = cm_data.get('execution_time_seconds', 30)
        resource_cost = cm_data.get('resource_cost', 'medium')
        risk_level = cm_data.get('risk_level', 'medium')
        
        # Check for side effects
        side_effects = cm_data.get('side_effects', [])
        
        # Simulate success probability (higher effectiveness = higher success)
        success_probability = simulated_effectiveness / 100.0
        success = random.random() < success_probability
        
        result = {
            'measure_type': measure_type,
            'target_source': target_source_id,
            'simulated_effectiveness': simulated_effectiveness,
            'execution_time_seconds': execution_time,
            'resource_cost': resource_cost,
            'risk_level': risk_level,
            'success_probability': success_probability * 100,
            'simulated_success': success,
            'side_effects': side_effects
        }
        
        return result
    
    def _calculate_overall_effectiveness(self, results: List[Dict]) -> float:
        """Calculate overall plan effectiveness"""
        if not results:
            return 0.0
        
        # Average effectiveness weighted by success probability
        total_weighted = sum(
            r['simulated_effectiveness'] * r['success_probability'] / 100
            for r in results
        )
        
        overall = total_weighted / len(results)
        return round(overall, 1)
    
    def _build_simulation_report(
        self,
        plan_id: str,
        results: List[Dict],
        overall_effectiveness: float,
        data: Dict
    ) -> str:
        """Build countermeasure simulation report"""
        
        report_lines = [
            "=" * 70,
            "COUNTERMEASURE SIMULATION REPORT",
            "=" * 70,
            f"Plan ID: {plan_id}",
            f"Countermeasures Simulated: {len(results)}",
            f"Overall Effectiveness: {overall_effectiveness:.1f}%",
            ""
        ]
        
        # Overall assessment
        assessment = self._assess_plan_viability(overall_effectiveness, results)
        report_lines.extend([
            "PLAN VIABILITY ASSESSMENT:",
            "-" * 70,
            f"  Viability: {assessment['viability']}",
            f"  Success Likelihood: {assessment['likelihood']}",
            f"  Recommendation: {assessment['recommendation']}",
            ""
        ])
        
        # Individual countermeasure results
        report_lines.extend([
            "INDIVIDUAL COUNTERMEASURE SIMULATIONS:",
            "-" * 70
        ])
        
        for idx, result in enumerate(results, 1):
            measure_name = result['measure_type'].replace('_', ' ').title()
            effectiveness = result['simulated_effectiveness']
            success_prob = result['success_probability']
            exec_time = result['execution_time_seconds']
            
            success_indicator = "SUCCESS" if result['simulated_success'] else "FAILURE"
            
            report_lines.extend([
                "",
                f"Countermeasure #{idx}: {measure_name}",
                f"  Effectiveness: {effectiveness:.1f}%",
                f"  Success Probability: {success_prob:.1f}%",
                f"  Simulated Outcome: {success_indicator}",
                f"  Execution Time: {exec_time} seconds",
                f"  Resource Cost: {result['resource_cost'].upper()}",
                f"  Risk Level: {result['risk_level'].upper()}"
            ])
            
            if result.get('target_source'):
                report_lines.append(f"  Target: {result['target_source']}")
            
            # Side effects
            if result['side_effects']:
                report_lines.append(f"  Side Effects:")
                for effect in result['side_effects']:
                    report_lines.append(f"    - {effect.replace('_', ' ').title()}")
        
        # Execution timeline
        report_lines.extend([
            "",
            "EXECUTION TIMELINE:",
            "-" * 70
        ])
        
        cumulative_time = 0
        for idx, result in enumerate(results, 1):
            measure_name = result['measure_type'].replace('_', ' ').title()
            exec_time = result['execution_time_seconds']
            cumulative_time += exec_time
            
            report_lines.append(
                f"  T+{cumulative_time}s: {measure_name} completed"
            )
        
        report_lines.append(f"\n  Total Execution Time: {cumulative_time} seconds")
        
        # Final recommendation
        report_lines.extend([
            "",
            "=" * 70,
            "SIMULATION CONCLUSION:",
            f"  Plan Effectiveness: {overall_effectiveness:.1f}%",
            f"  Viability: {assessment['viability']}",
            f"  {assessment['recommendation']}",
            "=" * 70
        ])
        
        return "\n".join(report_lines)
    
    def _assess_plan_viability(
        self,
        overall_effectiveness: float,
        results: List[Dict]
    ) -> Dict:
        """Assess plan viability based on simulation"""
        
        # Count successful simulations
        successful = sum(1 for r in results if r['simulated_success'])
        success_rate = (successful / len(results)) * 100 if results else 0
        
        if overall_effectiveness >= 80 and success_rate >= 70:
            return {
                'viability': 'EXCELLENT',
                'likelihood': f'{success_rate:.0f}% of countermeasures succeed',
                'recommendation': 'Plan is highly effective - APPROVED for execution'
            }
        elif overall_effectiveness >= 60 and success_rate >= 50:
            return {
                'viability': 'GOOD',
                'likelihood': f'{success_rate:.0f}% of countermeasures succeed',
                'recommendation': 'Plan is viable - APPROVED with minor risk'
            }
        elif overall_effectiveness >= 40:
            return {
                'viability': 'ACCEPTABLE',
                'likelihood': f'{success_rate:.0f}% of countermeasures succeed',
                'recommendation': 'Plan meets minimum threshold - APPROVED for consideration'
            }
        else:
            return {
                'viability': 'MARGINAL',
                'likelihood': f'{success_rate:.0f}% of countermeasures succeed',
                'recommendation': 'Plan effectiveness below threshold - Consider alternatives'
            }