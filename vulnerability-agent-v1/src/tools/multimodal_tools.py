"""
Multimodal input processing tools for vulnerability assessment.
Expanded to simulate EW sensor inputs (ESM, ELINT, Radar, GNSS receivers).

Tools for:
    - Audio transcription (inherited)
    - Document analysis (inherited)
    - Input type determination (inherited)
    - Radar signal processing (inherited)
    - EW signal processing (expanded for jamming)
    - ESM sensor simulation (NEW)
    - ELINT sensor simulation (NEW)
    - GNSS receiver simulation (NEW)
"""

import os
import json
import tempfile
from typing import Any, Optional, Type, List, Dict
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from pathlib import Path
import subprocess

from src.utils.logger import get_logger

logger = get_logger(__name__)


# ============================================================================
# INPUT SCHEMAS FOR PYDANTIC VALIDATION
# ============================================================================

class AudioTranscriptionInput(BaseModel):
    """Input schema for audio transcription."""
    audio_path: str = Field(
        ...,
        description="Path to the audio file to transcribe (mp3, wav, m4a, etc.)"
    )


class DocumentAnalysisInput(BaseModel):
    """Input schema for document analysis."""
    document_path: str = Field(
        ...,
        description="Path to the document file to analyze (txt, pdf)"
    )


class InputTypeDeterminerInput(BaseModel):
    """Input schema for input type determination."""
    input_data: str = Field(
        ...,
        description="File path or direct text content to analyze"
    )


class RadarSignalInput(BaseModel):
    """Input schema for radar signal processing."""
    signal_data: str = Field(
        ...,
        description="JSON string or file path containing radar detection data"
    )


class EWSignalInput(BaseModel):
    """Input schema for electronic warfare signal processing."""
    signal_data: str = Field(
        ...,
        description="JSON string or file path containing EW signal data (jamming attacks)"
    )


class ESMSensorInput(BaseModel):
    """Input schema for ESM sensor simulation."""
    attack_data: str = Field(
        ...,
        description="JSON string or file path with attack scenario data"
    )


class ELINTSensorInput(BaseModel):
    """Input schema for ELINT sensor simulation."""
    attack_data: str = Field(
        ...,
        description="JSON string or file path with attack scenario data"
    )


class GNSSSensorInput(BaseModel):
    """Input schema for GNSS receiver simulation."""
    attack_data: str = Field(
        ...,
        description="JSON string or file path with attack scenario data"
    )


# ============================================================================
# AUDIO TRANSCRIPTION TOOL (PRESERVED FROM ORIGINAL)
# ============================================================================

class AudioTranscriptionTool(BaseTool):
    """Transcribes audio files into text with speaker diarization"""
    name: str = "Audio Transcription Tool"
    description: str = (
        "Transcribes audio files (mp3, wav, m4a, etc.) into text for threat analysis. "
        "Includes speaker diarization using pyannote.audio. "
        "Input: audio_path (string - path to audio file)"
    )
    args_schema: Type[BaseModel] = AudioTranscriptionInput
    
    whisper_model: Optional[Any] = None
    diarization_pipeline: Optional[Any] = None

    def _load_whisper_model(self):
        """Lazy load whisper model only when needed"""
        if self.whisper_model is None:
            try:
                import whisper
                logger.info("Loading Whisper model...")
                self.whisper_model = whisper.load_model("base")
                logger.info("Whisper model loaded successfully")
            except ImportError:
                logger.error("Whisper not installed")
                raise ImportError(
                    "Whisper is not installed. Install it with: pip install openai-whisper"
                )
        return self.whisper_model

    def _load_diarization_pipeline(self):
        """Lazy load diarization pipeline only when needed"""
        if self.diarization_pipeline is None:
            try:
                from pyannote.audio import Pipeline
                hf_token = os.getenv("HF_TOKEN", None)
                
                if not hf_token:
                    logger.error("HF_TOKEN not found in environment")
                    raise ValueError(
                        "HF_TOKEN not found in environment. "
                        "Get your token from https://huggingface.co/settings/tokens"
                    )
                
                logger.info("Loading pyannote speaker-diarization model...")
                self.diarization_pipeline = Pipeline.from_pretrained(
                    "pyannote/speaker-diarization-3.1",
                    use_auth_token=hf_token
                )
                logger.info("Diarization model loaded successfully")

            except Exception as e:
                error_msg = str(e)
                if "gated" in error_msg.lower() or "private" in error_msg.lower():
                    logger.error("Authentication failed for pyannote model")
                    raise ValueError(
                        "Authentication failed for pyannote model."
                    )

                logger.error(f"Pyannote dependencies not available: {e}")
                raise ImportError(
                    f"Pyannote.audio dependencies not available: {e}\n"
                    "This may be due to PyTorch compatibility issues on your system."
                )
        return self.diarization_pipeline
    
    def _run(self, audio_path: str) -> str:
        try:
            logger.info(f"Starting audio transcription for: {audio_path}")
            
            if not os.path.exists(audio_path):
                logger.error(f"Audio file not found: {audio_path}")
                return f"Error: Audio file not found at {audio_path}"

            # Step 1: Execute diarization
            try:
                diar_pipeline = self._load_diarization_pipeline()
                model = self._load_whisper_model()
            except (ImportError, RuntimeError, OSError) as e:
                logger.error(f"Audio transcription dependencies error: {e}")
                return (
                    f"ERROR: Audio transcription dependencies not available\n"
                    f"Details: {str(e)}\n\n"
                    f"WORKAROUND: Audio transcription requires:\n"
                    f"1. Working PyTorch installation\n"
                    f"2. pyannote.audio\n"
                    f"3. HuggingFace token (HF_TOKEN in .env)\n\n"
                )
            
            NUM_SPEAKERS = 2  # Force 2 speakers for military conversations
            logger.debug(f"Running diarization with {NUM_SPEAKERS} speakers")
            diarization = diar_pipeline(audio_path, num_speakers=NUM_SPEAKERS)

            # Step 2: Load Whisper model
            model = self._load_whisper_model()

            # Step 3: Create speaker-labeled text
            segments = []
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                start, end = turn.start, turn.end
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_segment:
                    # Extract corresponding segment
                    subprocess.run([
                        "ffmpeg", "-y", "-i", audio_path,
                        "-ss", str(start), "-to", str(end),
                        "-ar", "16000", "-ac", "1", tmp_segment.name
                    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    result = model.transcribe(tmp_segment.name, language=None)
                    transcription = result["text"].strip()
                    if transcription:
                        segments.append(f"{speaker}: {transcription}")

            full_transcription = "\n".join(segments)
            logger.info(f"Transcription completed: {len(segments)} segments")

            formatted_output = f"""
AUDIO TRANSCRIPTION REPORT:
==========================
Speakers detected: {NUM_SPEAKERS}
Transcription:
{full_transcription}
==========================
            """
            return formatted_output.strip()

        except Exception as e:
            logger.error(f"Error processing audio file: {e}", exc_info=True)
            return f"Error processing audio file: {str(e)}"


# ============================================================================
# DOCUMENT ANALYSIS TOOL (PRESERVED FROM ORIGINAL)
# ============================================================================

class DocumentAnalysisTool(BaseTool):
    name: str = "Document Analysis Tool"
    description: str = (
        "Analyzes text documents, PDFs, and other written reports for threat intelligence. "
        "Input: document_path (string - path to document file)"
    )
    args_schema: Type[BaseModel] = DocumentAnalysisInput
    
    def _run(self, document_path: str) -> str:
        try:
            logger.info(f"Analyzing document: {document_path}")
            
            if not os.path.exists(document_path):
                logger.error(f"Document not found: {document_path}")
                return f"Error: Document file not found at {document_path}"
            
            file_extension = Path(document_path).suffix.lower()
            
            if file_extension == '.txt':
                content = self._read_text_file(document_path)
            elif file_extension == '.pdf':
                content = self._read_pdf_file(document_path)
            else:
                logger.warning(f"Unsupported document type: {file_extension}")
                return f"Unsupported document type: {file_extension}"
            
            logger.info(f"Document analyzed successfully: {len(content)} characters")
            
            formatted_output = f"""
DOCUMENT ANALYSIS REPORT:
========================
File: {os.path.basename(document_path)}

Content:
{content}
========================
            """
            return formatted_output.strip()
            
        except Exception as e:
            logger.error(f"Error processing document: {e}", exc_info=True)
            return f"Error processing document: {str(e)}"
    
    def _read_text_file(self, file_path: str) -> str:
        """Read plain text file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except Exception as e:
            logger.error(f"Error reading text file: {e}")
            return f"Error reading text file: {str(e)}"
    
    def _read_pdf_file(self, file_path: str) -> str:
        """Read PDF file using PyPDF2"""
        try:
            import PyPDF2
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text()
                return text
        except ImportError:
            logger.error("PyPDF2 not installed")
            return "PDF processing requires PyPDF2: pip install PyPDF2"
        except Exception as e:
            logger.error(f"Error reading PDF: {e}")
            return f"Error reading PDF file: {str(e)}"


# ============================================================================
# INPUT TYPE DETERMINER TOOL (PRESERVED FROM ORIGINAL)
# ============================================================================

class InputTypeDeterminerTool(BaseTool):
    name: str = "Input Type Determiner"
    description: str = (
        "Determines the type of input (text, audio, image, document, radar, EW signal) and recommends which processing tool to use. "
        "Input: input_data (string - file path or direct text content)"
    )
    args_schema: Type[BaseModel] = InputTypeDeterminerInput
    
    def _run(self, input_data: str) -> str:
        logger.debug(f"Determining input type for: {input_data[:100]}...")
        
        # Check if it's a file path
        if os.path.exists(input_data):
            file_path = input_data
            file_extension = Path(file_path).suffix.lower()
            
            # Audio formats
            if file_extension in ['.mp3', '.wav', '.m4a', '.flac', '.ogg']:
                logger.info(f"Detected audio file: {file_extension}")
                return f"""
INPUT TYPE: AUDIO FILE
Detected: {file_extension.upper()} audio file
Recommendation: Use Audio Transcription Tool to convert to text
File: {os.path.basename(file_path)}
                """
        
            # Document formats
            elif file_extension in ['.txt', '.pdf', '.doc', '.docx']:
                logger.info(f"Detected document file: {file_extension}")
                return f"""
INPUT TYPE: DOCUMENT FILE
Detected: {file_extension.upper()} document file
Recommendation: Use Document Analysis Tool to process text content
File: {os.path.basename(file_path)}
                """
            
            # JSON (could be attack data)
            elif file_extension == '.json':
                logger.info("Detected JSON file - checking for attack data")
                try:
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                        if 'sources' in data or 'attack_type' in data:
                            return f"""
INPUT TYPE: ATTACK DATA (JSON)
Detected: Electronic warfare attack data in JSON format
Recommendation: Use ESM/ELINT sensor tools or EW Signal Processor
File: {os.path.basename(file_path)}
                            """
                except:
                    pass
                return f"""
INPUT TYPE: JSON FILE
Detected: Generic JSON data file
Recommendation: Process as structured data
File: {os.path.basename(file_path)}
                """
            
            # Image formats
            elif file_extension in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']:
                logger.info(f"Detected image file: {file_extension}")
                return f"""
INPUT TYPE: IMAGE FILE
Detected: {file_extension.upper()} image file
Recommendation: Process image for visual threat intelligence
File: {os.path.basename(file_path)}
                """
            
            else:
                logger.warning(f"Unknown file type: {file_extension}")
                return f"""
INPUT TYPE: UNKNOWN FILE
Detected: {file_extension.upper()} file (unsupported format)
File: {os.path.basename(file_path)}
                """
        
        # Try to parse as JSON (attack data)
        try:
            data = json.loads(input_data)
            if isinstance(data, dict) and ('sources' in data or 'attack_type' in data):
                logger.info("Detected inline attack data (JSON)")
                return """
INPUT TYPE: ATTACK DATA (INLINE JSON)
Detected: Electronic warfare attack data as JSON string
Recommendation: Use ESM/ELINT sensor tools or EW Signal Processor
                """
        except json.JSONDecodeError:
            pass
        
        # Assume it's direct text input
        word_count = len(input_data.split())
        logger.info(f"Detected direct text input: {word_count} words")
        return f"""
INPUT TYPE: DIRECT TEXT
Detected: Text input with {word_count} words
Recommendation: Process directly for threat analysis
        """


# ============================================================================
# RADAR SIGNAL PROCESSOR (PRESERVED FROM ORIGINAL)
# ============================================================================

class RadarSignalProcessor(BaseTool):
    """Processes radar detection data for naval electronic warfare analysis"""
    name: str = "Radar Signal Processor"
    description: str = (
        "Processes radar and ESM detection data to identify electromagnetic emitters. "
        "Extracts emitter characteristics including type, frequency, power, and bearing. "
        "Input: signal_data (JSON string or file path with radar detections)"
    )
    args_schema: Type[BaseModel] = RadarSignalInput
    
    def _run(self, signal_data: str) -> str:
        try:
            logger.info("Processing radar signal data")
            
            data = self._parse_signal_data(signal_data)
            
            if not data:
                logger.error("Failed to parse signal data")
                return "ERROR: Could not parse radar signal data"
            
            detections = data.get('detections', [])
            if not detections:
                logger.warning("No detections found in signal data")
                return "NO DETECTIONS: No emitters detected in provided data"
            
            logger.info(f"Processing {len(detections)} detections")
            
            processed_detections = []
            for det in detections:
                processed = {
                    'emitter_id': det.get('emitter_id', 'UNKNOWN'),
                    'type': det.get('emitter_type', 'unknown'),
                    'frequency': f"{det.get('frequency_mhz', 0):.2f} MHz",
                    'power': f"{det.get('power_dbm', 0):.1f} dBm",
                    'bearing': f"{det.get('bearing_degrees', 0):.1f}°" if det.get('bearing_degrees') else "Unknown",
                    'range': f"{det.get('range_km', 0):.1f} km" if det.get('range_km') else "Unknown",
                    'classification': det.get('classification', 'Unclassified')
                }
                processed_detections.append(processed)
            
            report = self._build_radar_report(processed_detections, data)
            logger.info("Radar signal processing completed")
            
            return report
            
        except Exception as e:
            logger.error(f"Error processing radar signals: {e}", exc_info=True)
            return f"ERROR processing radar data: {str(e)}"
    
    def _parse_signal_data(self, signal_data: str) -> Optional[Dict]:
        """Parse signal data from file or JSON string"""
        try:
            if os.path.exists(signal_data):
                logger.debug(f"Reading signal data from file: {signal_data}")
                with open(signal_data, 'r') as f:
                    return json.load(f)
            
            logger.debug("Parsing signal data as JSON string")
            return json.loads(signal_data)
        
        except Exception as e:
            logger.error(f"Failed to parse signal data: {e}")
            return None
    
    def _build_radar_report(self, detections: List[Dict], raw_data: Dict) -> str:
        """Build formatted radar detection report"""
        
        sensor_type = raw_data.get('sensor_type', 'Unknown')
        mode = raw_data.get('operational_mode', 'normal')
        
        report_lines = [
            "=" * 70,
            "RADAR SIGNAL INTELLIGENCE REPORT",
            "=" * 70,
            f"Sensor Type: {sensor_type.upper()}",
            f"Operational Mode: {mode.upper()}",
            f"Total Detections: {len(detections)}",
            "",
            "DETECTED EMITTERS:",
            "-" * 70
        ]
        
        for det in detections:
            report_lines.extend([
                "",
                f"Emitter ID: {det['emitter_id']}",
                f"  Type: {det['type']}",
                f"  Classification: {det['classification']}",
                f"  Frequency: {det['frequency']}",
                f"  Power: {det['power']}",
                f"  Bearing: {det['bearing']}",
                f"  Range: {det['range']}"
            ])
        
        report_lines.extend([
            "",
            "=" * 70,
            "SUMMARY: Radar detections processed and ready for threat assessment"
        ])
        
        return "\n".join(report_lines)


# ============================================================================
# EW SIGNAL PROCESSOR (EXPANDED FOR JAMMING ATTACKS)
# ============================================================================

class EWSignalProcessor(BaseTool):
    """Processes electronic warfare signal data including jamming and interference"""
    name: str = "EW Signal Processor"
    description: str = (
        "Processes electronic warfare signals including jamming, interference, and hostile emissions. "
        "Identifies jamming sources, characterizes attack patterns, and analyzes network anomalies. "
        "Input: signal_data (JSON string or file path with EW attack data)"
    )
    args_schema: Type[BaseModel] = EWSignalInput
    
    def _run(self, signal_data: str) -> str:
        try:
            logger.info("Processing EW signal data (jamming attack)")
            
            data = self._parse_signal_data(signal_data)
            
            if not data:
                logger.error("Failed to parse EW signal data")
                return "ERROR: Could not parse EW signal data"
            
            # Extract jamming sources
            sources = data.get('sources', [])
            network_anomalies = data.get('network_anomalies', {})
            attack_type = data.get('attack_type', 'unknown')
            
            if not sources:
                logger.warning("No jamming sources detected")
                return "NO THREATS: No electronic warfare activity detected"
            
            logger.info(f"Processing {len(sources)} jamming sources")
            
            report = self._build_ew_report(sources, network_anomalies, attack_type, data)
            logger.info("EW signal processing completed")
            
            return report
            
        except Exception as e:
            logger.error(f"Error processing EW signals: {e}", exc_info=True)
            return f"ERROR processing EW data: {str(e)}"
    
    def _parse_signal_data(self, signal_data: str) -> Optional[Dict]:
        """Parse EW signal data from file or JSON string"""
        try:
            if os.path.exists(signal_data):
                logger.debug(f"Reading EW data from file: {signal_data}")
                with open(signal_data, 'r') as f:
                    return json.load(f)
            
            logger.debug("Parsing EW data as JSON string")
            return json.loads(signal_data)
        
        except Exception as e:
            logger.error(f"Failed to parse EW data: {e}")
            return None
    
    def _build_ew_report(
        self,
        sources: List[Dict],
        network_anomalies: Dict,
        attack_type: str,
        raw_data: Dict
    ) -> str:
        """Build formatted EW threat report"""
        
        timestamp = raw_data.get('timestamp', 'Unknown')
        
        report_lines = [
            "=" * 70,
            "ELECTRONIC WARFARE ATTACK REPORT",
            "=" * 70,
            f"Attack Type: {attack_type.upper()}",
            f"Detection Time: {timestamp}",
            f"Total Jamming Sources: {len(sources)}",
            ""
        ]
        
        # Network anomalies
        if network_anomalies:
            report_lines.extend([
                "NETWORK ANOMALIES DETECTED:",
                "-" * 70,
                f"  Packet Loss: {network_anomalies.get('packet_loss', 0)}%",
                f"  Latency Increase: {network_anomalies.get('latency_increase', 0)} ms",
                f"  Corrupted Frames: {network_anomalies.get('corrupted_frames', 0)}",
                f"  Connection Drops: {network_anomalies.get('connection_drops', 0)}",
                ""
            ])
        
        # Jamming sources
        report_lines.extend([
            "JAMMING SOURCES:",
            "-" * 70
        ])
        
        for source in sources:
            location = source.get('location', {})
            affected = ', '.join(source.get('affected_systems', []))
            
            report_lines.extend([
                "",
                f"Source ID: {source.get('source_id', 'UNKNOWN')}",
                f"  Jamming Type: {source.get('jamming_type', 'unknown').upper()}",
                f"  Location: Lat {location.get('lat', 0):.4f}, Lon {location.get('lon', 0):.4f}",
                f"  Frequency: {source.get('frequency_mhz', 0):.2f} MHz",
                f"  Power: {source.get('power_dbm', 0):.1f} dBm",
                f"  Affected Systems: {affected}"
            ])
            
            if source.get('bearing_degrees'):
                report_lines.append(f"  Bearing: {source['bearing_degrees']:.1f}°")
            if source.get('range_km'):
                report_lines.append(f"  Range: {source['range_km']:.1f} km")
        
        report_lines.extend([
            "",
            "=" * 70,
            "SUMMARY: EW jamming attack identified - immediate countermeasure required"
        ])
        
        return "\n".join(report_lines)


# ============================================================================
# NEW: ESM SENSOR SIMULATOR
# ============================================================================

class ESMSensorSimulator(BaseTool):
    """Simulates ESM (Electronic Support Measures) sensor passive detection"""
    name: str = "ESM Sensor Simulator"
    description: str = (
        "Simulates passive ESM sensor detection of hostile electromagnetic emissions. "
        "ESM systems passively intercept, locate, and analyze jamming sources. "
        "Input: attack_data (JSON string or file path with attack scenario)"
    )
    args_schema: Type[BaseModel] = ESMSensorInput
    
    def _run(self, attack_data: str) -> str:
        try:
            logger.info("Simulating ESM sensor detection")
            
            data = self._parse_attack_data(attack_data)
            
            if not data:
                return "ERROR: Could not parse attack data for ESM simulation"
            
            sources = data.get('sources', [])
            
            if not sources:
                return "ESM SENSOR: No hostile emissions detected"
            
            logger.info(f"ESM detected {len(sources)} hostile emitters")
            
            report = self._build_esm_report(sources, data)
            return report
            
        except Exception as e:
            logger.error(f"ESM simulation error: {e}", exc_info=True)
            return f"ERROR in ESM sensor: {str(e)}"
    
    def _parse_attack_data(self, attack_data: str) -> Optional[Dict]:
        """Parse attack data"""
        try:
            if os.path.exists(attack_data):
                with open(attack_data, 'r') as f:
                    return json.load(f)
            return json.loads(attack_data)
        except Exception as e:
            logger.error(f"Failed to parse attack data: {e}")
            return None
    
    def _build_esm_report(self, sources: List[Dict], data: Dict) -> str:
        """Build ESM detection report"""
        
        report_lines = [
            "=" * 70,
            "ESM SENSOR DETECTION REPORT",
            "=" * 70,
            f"Sensor Status: OPERATIONAL",
            f"Detection Mode: PASSIVE INTERCEPT",
            f"Hostile Emissions Detected: {len(sources)}",
            ""
        ]
        
        for idx, source in enumerate(sources, 1):
            location = source.get('location', {})
            
            report_lines.extend([
                f"EMITTER #{idx}:",
                f"  Source ID: {source.get('source_id', 'UNKNOWN')}",
                f"  Frequency: {source.get('frequency_mhz', 0):.2f} MHz",
                f"  Power Level: {source.get('power_dbm', 0):.1f} dBm",
                f"  Signal Type: {source.get('jamming_type', 'unknown').upper()}",
                f"  Estimated Location: {location.get('lat', 0):.4f}N, {location.get('lon', 0):.4f}E",
                ""
            ])
        
        report_lines.extend([
            "=" * 70,
            "ESM ASSESSMENT: Hostile jamming emissions confirmed",
            "RECOMMENDATION: Initiate countermeasure evaluation"
        ])
        
        return "\n".join(report_lines)


# ============================================================================
# NEW: ELINT SENSOR SIMULATOR
# ============================================================================

class ELINTSensorSimulator(BaseTool):
    """Simulates ELINT (Electronic Intelligence) sensor for detailed signal analysis"""
    name: str = "ELINT Sensor Simulator"
    description: str = (
        "Simulates ELINT sensor providing detailed technical intelligence on hostile signals. "
        "ELINT focuses on detailed signal characteristics and emitter fingerprinting. "
        "Input: attack_data (JSON string or file path with attack scenario)"
    )
    args_schema: Type[BaseModel] = ELINTSensorInput
    
    def _run(self, attack_data: str) -> str:
        try:
            logger.info("Simulating ELINT sensor analysis")
            
            data = self._parse_attack_data(attack_data)
            
            if not data:
                return "ERROR: Could not parse attack data for ELINT simulation"
            
            sources = data.get('sources', [])
            
            if not sources:
                return "ELINT SENSOR: No signals for detailed analysis"
            
            logger.info(f"ELINT analyzing {len(sources)} signals in detail")
            
            report = self._build_elint_report(sources, data)
            return report
            
        except Exception as e:
            logger.error(f"ELINT simulation error: {e}", exc_info=True)
            return f"ERROR in ELINT sensor: {str(e)}"
    
    def _parse_attack_data(self, attack_data: str) -> Optional[Dict]:
        """Parse attack data"""
        try:
            if os.path.exists(attack_data):
                with open(attack_data, 'r') as f:
                    return json.load(f)
            return json.loads(attack_data)
        except Exception as e:
            logger.error(f"Failed to parse attack data: {e}")
            return None
    
    def _build_elint_report(self, sources: List[Dict], data: Dict) -> str:
        """Build ELINT technical intelligence report"""
        
        report_lines = [
            "=" * 70,
            "ELINT TECHNICAL INTELLIGENCE REPORT",
            "=" * 70,
            f"Sensor Status: OPERATIONAL",
            f"Analysis Mode: DETAILED SIGNAL CHARACTERIZATION",
            f"Signals Under Analysis: {len(sources)}",
            ""
        ]
        
        for idx, source in enumerate(sources, 1):
            jamming_type = source.get('jamming_type', 'unknown')
            bandwidth = source.get('bandwidth_mhz', 0)
            
            # Technical characteristics based on jamming type
            technical_details = self._get_technical_characteristics(jamming_type)
            
            report_lines.extend([
                f"SIGNAL #{idx} - TECHNICAL ANALYSIS:",
                f"  Source ID: {source.get('source_id', 'UNKNOWN')}",
                f"  Center Frequency: {source.get('frequency_mhz', 0):.2f} MHz",
                f"  Bandwidth: {bandwidth:.2f} MHz" if bandwidth else "  Bandwidth: Not determined",
                f"  Power Output: {source.get('power_dbm', 0):.1f} dBm",
                f"  Modulation: {technical_details['modulation']}",
                f"  Jamming Technique: {jamming_type.upper()}",
                f"  Signal Characteristics: {technical_details['characteristics']}",
                f"  Threat Classification: {technical_details['threat']}",
                ""
            ])
        
        report_lines.extend([
            "=" * 70,
            "ELINT CONCLUSION: Technical parameters extracted for countermeasure design",
            "RECOMMENDATION: Use data for precision countermeasure targeting"
        ])
        
        return "\n".join(report_lines)
    
    def _get_technical_characteristics(self, jamming_type: str) -> Dict[str, str]:
        """Get technical characteristics based on jamming type"""
        characteristics = {
            'barrage': {
                'modulation': 'Wideband Noise',
                'characteristics': 'High power across wide spectrum, low spectral density',
                'threat': 'HIGH - Multiple systems affected'
            },
            'spot': {
                'modulation': 'Narrowband Continuous Wave',
                'characteristics': 'High power concentrated on target frequency',
                'threat': 'CRITICAL - Precise targeting of key systems'
            },
            'sweep': {
                'modulation': 'Frequency-swept tone',
                'characteristics': 'Time-varying frequency, repetitive pattern',
                'threat': 'HIGH - Covers multiple frequencies sequentially'
            },
            'deceptive': {
                'modulation': 'Signal mimicry',
                'characteristics': 'Matches legitimate signal characteristics',
                'threat': 'CRITICAL - False information injection'
            },
            'pulse': {
                'modulation': 'Pulsed RF',
                'characteristics': 'High peak power, low duty cycle',
                'threat': 'MEDIUM - Intermittent disruption'
            },
            'noise': {
                'modulation': 'Gaussian noise',
                'characteristics': 'Random spectrum, broadband',
                'threat': 'MEDIUM - SNR degradation'
            },
            'follower': {
                'modulation': 'Adaptive/Cognitive',
                'characteristics': 'Tracks frequency changes, intelligent targeting',
                'threat': 'CRITICAL - Defeats standard countermeasures'
            }
        }
        
        return characteristics.get(
            jamming_type.lower(),
            {
                'modulation': 'Unknown',
                'characteristics': 'Unclassified signal pattern',
                'threat': 'UNKNOWN'
            }
        )


# ============================================================================
# NEW: GNSS RECEIVER SIMULATOR
# ============================================================================

class GNSSReceiverSimulator(BaseTool):
    """Simulates GNSS (GPS/GLONASS) receiver detecting spoofing attacks"""
    name: str = "GNSS Receiver Simulator"
    description: str = (
        "Simulates GNSS receiver detecting jamming or spoofing attacks on navigation systems. "
        "Detects anomalies in GPS/GLONASS signals including signal loss and false positioning. "
        "Input: attack_data (JSON string or file path with attack scenario)"
    )
    args_schema: Type[BaseModel] = GNSSSensorInput
    
    def _run(self, attack_data: str) -> str:
        try:
            logger.info("Simulating GNSS receiver status")
            
            data = self._parse_attack_data(attack_data)
            
            if not data:
                return "ERROR: Could not parse attack data for GNSS simulation"
            
            sources = data.get('sources', [])
            
            # Check if navigation systems are affected
            gnss_affected = False
            for source in sources:
                affected_systems = source.get('affected_systems', [])
                if 'navigation' in affected_systems:
                    gnss_affected = True
                    break
            
            report = self._build_gnss_report(gnss_affected, sources, data)
            return report
            
        except Exception as e:
            logger.error(f"GNSS simulation error: {e}", exc_info=True)
            return f"ERROR in GNSS receiver: {str(e)}"
    
    def _parse_attack_data(self, attack_data: str) -> Optional[Dict]:
        """Parse attack data"""
        try:
            if os.path.exists(attack_data):
                with open(attack_data, 'r') as f:
                    return json.load(f)
            return json.loads(attack_data)
        except Exception as e:
            logger.error(f"Failed to parse attack data: {e}")
            return None
    
    def _build_gnss_report(
        self,
        gnss_affected: bool,
        sources: List[Dict],
        data: Dict
    ) -> str:
        """Build GNSS receiver status report"""
        
        report_lines = [
            "=" * 70,
            "GNSS RECEIVER STATUS REPORT",
            "=" * 70,
            f"Receiver Status: OPERATIONAL"
        ]
        
        if gnss_affected:
            report_lines.extend([
                f"ALERT: GNSS SIGNAL DEGRADATION DETECTED",
                "",
                "ANOMALIES DETECTED:",
                "  ⚠ Signal interference on L1 frequency (1575 MHz)",
                "  ⚠ Multiple conflicting position solutions",
                "  ⚠ Signal strength abnormally high (possible spoofing)",
                "  ⚠ Clock drift exceeds normal parameters",
                "",
                "AFFECTED SYSTEMS:",
                "  • GPS L1/L2 signals: DEGRADED",
                "  • GLONASS: DEGRADED",
                "  • Position accuracy: COMPROMISED",
                "",
                "NAVIGATION STATUS: UNRELIABLE",
                "",
                "RECOMMENDATION:",
                "  → Switch to inertial navigation (INS)",
                "  → Cross-reference with celestial navigation",
                "  → Deploy GNSS anti-jam countermeasures",
                "  → Identify and neutralize jamming source"
            ])
        else:
            report_lines.extend([
                f"GNSS Signal Status: NOMINAL",
                "",
                "GPS L1/L2: LOCKED - 8 satellites tracked",
                "GLONASS: LOCKED - 6 satellites tracked",
                "Position Accuracy: ±3 meters (3D RMS)",
                "Time Sync: ACCURATE (UTC disciplined)",
                "",
                "NAVIGATION STATUS: OPERATIONAL",
                "",
                "No GNSS interference detected"
            ])
        
        report_lines.extend([
            "",
            "=" * 70
        ])
        
        return "\n".join(report_lines)


# ============================================================================
# NEW: COMMUNICATION RECEIVER SIMULATOR
# ============================================================================

class CommunicationReceiverSimulator(BaseTool):
    """Simulates communication receivers detecting jamming effects"""
    name: str = "Communication Receiver Simulator"
    description: str = (
        "Simulates ship communication receivers detecting jamming effects on radio/datalink. "
        "Reports signal degradation, connection quality, and affected channels. "
        "Input: attack_data (JSON string or file path with attack scenario)"
    )
    args_schema: Type[BaseModel] = ESMSensorInput  # Reuse schema
    
    def _run(self, attack_data: str) -> str:
        try:
            logger.info("Simulating communication receiver status")
            
            data = self._parse_attack_data(attack_data)
            
            if not data:
                return "ERROR: Could not parse attack data for comm simulation"
            
            sources = data.get('sources', [])
            network_anomalies = data.get('network_anomalies', {})
            
            # Check if communications are affected
            comms_affected = False
            for source in sources:
                affected_systems = source.get('affected_systems', [])
                if 'communications' in affected_systems or 'datalink' in affected_systems:
                    comms_affected = True
                    break
            
            report = self._build_comms_report(comms_affected, network_anomalies, sources)
            return report
            
        except Exception as e:
            logger.error(f"Comm receiver simulation error: {e}", exc_info=True)
            return f"ERROR in communication receivers: {str(e)}"
    
    def _parse_attack_data(self, attack_data: str) -> Optional[Dict]:
        """Parse attack data"""
        try:
            if os.path.exists(attack_data):
                with open(attack_data, 'r') as f:
                    return json.load(f)
            return json.loads(attack_data)
        except Exception as e:
            logger.error(f"Failed to parse attack data: {e}")
            return None
    
    def _build_comms_report(
        self,
        comms_affected: bool,
        network_anomalies: Dict,
        sources: List[Dict]
    ) -> str:
        """Build communication receiver status report"""
        
        report_lines = [
            "=" * 70,
            "COMMUNICATION RECEIVERS STATUS REPORT",
            "=" * 70
        ]
        
        if comms_affected:
            packet_loss = network_anomalies.get('packet_loss', 0)
            latency = network_anomalies.get('latency_increase', 0)
            corrupted = network_anomalies.get('corrupted_frames', 0)
            
            report_lines.extend([
                "ALERT: COMMUNICATION DEGRADATION DETECTED",
                "",
                "CHANNEL STATUS:",
                f"  • VHF Marine (156 MHz): JAMMED - Signal lost",
                f"  • UHF Tactical (225-400 MHz): DEGRADED - {packet_loss}% packet loss",
                f"  • Datalink (960-1215 MHz): DEGRADED - {latency}ms latency increase",
                f"  • HF Long Range: OPERATIONAL (backup)",
                "",
                "NETWORK METRICS:",
                f"  Packet Loss: {packet_loss}%",
                f"  Latency Increase: +{latency} ms",
                f"  Corrupted Frames: {corrupted}",
                f"  Effective Throughput: {100 - packet_loss}% of nominal",
                "",
                "COMMUNICATION STATUS: SEVERELY DEGRADED",
                "",
                "RECOMMENDATION:",
                "  → Switch to SATCOM backup channels",
                "  → Activate frequency hopping protocols",
                "  → Increase transmission power (burn-through)",
                "  → Deploy directional antennas"
            ])
        else:
            report_lines.extend([
                "Communication Status: NOMINAL",
                "",
                "CHANNEL STATUS:",
                "  • VHF Marine (156 MHz): OPERATIONAL - Clear",
                "  • UHF Tactical (225-400 MHz): OPERATIONAL - Clear",
                "  • SATCOM Primary: OPERATIONAL - Clear",
                "  • Datalink: OPERATIONAL - Clear",
                "",
                "NETWORK METRICS:",
                "  Packet Loss: <1%",
                "  Latency: Normal (<50ms)",
                "  Signal Quality: EXCELLENT",
                "",
                "COMMUNICATION STATUS: FULLY OPERATIONAL",
                "",
                "No interference detected on any channels"
            ])
        
        report_lines.extend([
            "",
            "=" * 70
        ])
        
        return "\n".join(report_lines)